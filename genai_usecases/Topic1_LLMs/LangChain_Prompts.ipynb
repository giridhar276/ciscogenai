{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42ab4f5d",
   "metadata": {},
   "source": [
    "# LangChain + OpenAI (Updated) — Prompts \n",
    "\n",
    "This notebook demonstrates **modern LangChain imports** (`langchain-openai`) and a variety of **prompting patterns** \n",
    "- Basic Q&A\n",
    "- Summarization (with constraints)\n",
    "- Classification (labels)\n",
    "- Information extraction (JSON)\n",
    "- Rewrite / tone change\n",
    "- Few-shot prompting\n",
    "- Prompt templates\n",
    "- Simple evaluation + retry\n",
    "- Batch processing over a list / DataFrame\n",
    "\n",
    "> **Important:** Never hardcode API keys in notebooks. Use `.env` or a secure prompt.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a78ad6",
   "metadata": {},
   "source": [
    "## 0) Install (run once)\n",
    "\n",
    "If you see version-mismatch errors (like `ensure_id` import issues), do a clean reinstall and **restart kernel**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4d1d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall -y langchain langchain-core langchain-community langchain-openai langchain-cohere >/dev/null 2>&1\n",
    "!pip install -U pip >/dev/null 2>&1\n",
    "!pip install -U \"langchain-core>=1.2.7\" \"langchain>=1.0.0\" \"langchain-openai\" \"python-dotenv\" pandas >/dev/null 2>&1\n",
    "print(\"Installed / upgraded packages. Now restart the kernel (Kernel -> Restart).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2f6981",
   "metadata": {},
   "source": [
    "## 1) Setup API key safely\n",
    "\n",
    "### Option A: `.env` file (recommended)\n",
    "\n",
    "Create a `.env` file in the same folder:\n",
    "```env\n",
    "OPENAI_API_KEY=your_key_here\n",
    "```\n",
    "\n",
    "### Option B: prompt for key \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7562ddbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Fallback: prompt if not already set\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    import getpass\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter OPENAI_API_KEY: \")\n",
    "\n",
    "print(\"OPENAI_API_KEY set:\", \"YES\" if os.environ.get(\"OPENAI_API_KEY\") else \"NO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abf7ed0",
   "metadata": {},
   "source": [
    "## 2) Create an LLM client (ChatOpenAI)\n",
    "\n",
    "- `temperature=0` for more deterministic answers\n",
    "- Choose a model you have access to (example: `gpt-4o-mini`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50794dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# A quick smoke test\n",
    "resp = llm.invoke(\"Give me a 1-line definition of Machine Learning.\")\n",
    "print(resp.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72311dea",
   "metadata": {},
   "source": [
    "## 3) Prompt Example: Basic Q&A with constraints\n",
    "\n",
    "Teach students to add constraints:\n",
    "- output length\n",
    "- formatting\n",
    "- audience level\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9453c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = '''\n",
    "Explain \"overfitting\" to a beginner.\n",
    "Constraints:\n",
    "- Exactly 3 bullet points\n",
    "- Each bullet <= 12 words\n",
    "- No jargon\n",
    "'''\n",
    "print(llm.invoke(prompt).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93cef3d3",
   "metadata": {},
   "source": [
    "## 4) Prompt Example: Summarization (with structure)\n",
    "\n",
    "Summarize text into a fixed template so outputs are consistent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1208b26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''\n",
    "LangChain is a framework for building applications with LLMs. It provides abstractions for prompts,\n",
    "models, tools, agents, memory, and retrieval. Recent versions split provider integrations into\n",
    "separate packages like langchain-openai, langchain-cohere, etc. This enables faster iteration\n",
    "and smaller dependency footprints.\n",
    "'''\n",
    "\n",
    "prompt = f'''\n",
    "Summarize the text below using this template:\n",
    "\n",
    "Title: <5-8 words>\n",
    "Key Points: (3 bullets)\n",
    "Action Item: (1 sentence)\n",
    "\n",
    "Text:\n",
    "{text}\n",
    "'''\n",
    "print(llm.invoke(prompt).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e71dc1",
   "metadata": {},
   "source": [
    "## 5) Prompt Example: Classification (label only)\n",
    "\n",
    "A common enterprise use-case: classify tickets/logs.\n",
    "\n",
    "Key teaching point: **force a closed set of labels** and ask for **only the label**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81be0906",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_log(message: str) -> str:\n",
    "    prompt = f'''\n",
    "Return exactly ONE label: INFO, WARNING, CRITICAL\n",
    "\n",
    "Rules:\n",
    "- failure/breach/outage/connection failed => CRITICAL\n",
    "- low disk/memory/latency/unstable => WARNING\n",
    "- otherwise => INFO\n",
    "\n",
    "Log: {message}\n",
    "Label:\n",
    "'''.strip()\n",
    "    return llm.invoke(prompt).content.strip().split()[0].upper()\n",
    "\n",
    "logs = [\n",
    "    \"INFO: Server started successfully\",\n",
    "    \"WARNING: Low disk space on /dev/sda1\",\n",
    "    \"CRITICAL: Database connection failed\",\n",
    "    \"User login succeeded\",\n",
    "]\n",
    "for l in logs:\n",
    "    print(l, \"->\", classify_log(l))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8350254d",
   "metadata": {},
   "source": [
    "## 6) Prompt Example: Extraction (return JSON only)\n",
    "\n",
    "Teach students to ask for **valid JSON** only (no commentary).\n",
    "We can later parse it reliably.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa22192",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "incident = '''\n",
    "Incident: INC12345\n",
    "Short Description: VPN not working for multiple users\n",
    "Description: Users report VPN disconnects every 2-3 minutes after the latest update.\n",
    "Impact: High, many teams blocked.\n",
    "Urgency: High\n",
    "'''\n",
    "\n",
    "prompt = f'''\n",
    "Extract the following fields as VALID JSON (no extra text):\n",
    "- incident_id\n",
    "- short_description\n",
    "- impact (Low/Medium/High)\n",
    "- urgency (Low/Medium/High)\n",
    "- likely_root_cause (1 sentence)\n",
    "\n",
    "Text:\n",
    "{incident}\n",
    "'''\n",
    "raw = llm.invoke(prompt).content.strip()\n",
    "print(raw)\n",
    "\n",
    "# Try parsing\n",
    "data = json.loads(raw)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28dbead",
   "metadata": {},
   "source": [
    "## 7) Prompt Example: Rewrite / tone transformation\n",
    "\n",
    "Useful for emails, tickets, or policy text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9d2226",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Hi team, vpn is down again. fix asap. this is very bad.\"\n",
    "\n",
    "prompt = f'''\n",
    "Rewrite the message in a professional corporate tone.\n",
    "Constraints:\n",
    "- 2 sentences\n",
    "- Include a polite request\n",
    "- Do not blame anyone\n",
    "\n",
    "Original:\n",
    "{text}\n",
    "'''\n",
    "print(llm.invoke(prompt).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c8f265",
   "metadata": {},
   "source": [
    "## 8) Few-shot prompting (show examples → get consistent outputs)\n",
    "\n",
    "Few-shot is very effective for teaching consistent labeling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e0228c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = '''\n",
    "You are a log severity classifier. Output exactly one label: INFO, WARNING, CRITICAL.\n",
    "\n",
    "Examples:\n",
    "Log: \"Disk usage is at 92% on server A\"\n",
    "Label: WARNING\n",
    "\n",
    "Log: \"Service cannot connect to database; connection refused\"\n",
    "Label: CRITICAL\n",
    "\n",
    "Log: \"Nightly backup completed successfully\"\n",
    "Label: INFO\n",
    "\n",
    "Now classify:\n",
    "Log: \"CPU is constantly at 98% for 10 minutes\"\n",
    "Label:\n",
    "'''.strip()\n",
    "\n",
    "print(llm.invoke(prompt).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7526c9a4",
   "metadata": {},
   "source": [
    "## 9) PromptTemplate (parameterized prompts)\n",
    "\n",
    "This is how you avoid manual string formatting and keep prompts reusable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4fe6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = PromptTemplate.from_template(\n",
    "    '''You are a helpful tutor.\n",
    "Explain {topic} for a {audience}.\n",
    "Constraints:\n",
    "- {bullets} bullet points\n",
    "- Each bullet <= {max_words} words\n",
    "- End with one short example\n",
    "'''\n",
    ")\n",
    "\n",
    "prompt = template.format(topic=\"Pandas DataFrame\", audience=\"beginner\", bullets=4, max_words=10)\n",
    "print(prompt)\n",
    "print(\"\\n---\\n\")\n",
    "print(llm.invoke(prompt).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33e611c",
   "metadata": {},
   "source": [
    "## 10) Simple \"guardrail\": validate output and retry\n",
    "\n",
    "Teaching point: you can programmatically check outputs.\n",
    "Example: ensure label is in allowed set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d152c754",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALLOWED = {\"INFO\", \"WARNING\", \"CRITICAL\"}\n",
    "\n",
    "def classify_with_retry(message: str, max_tries: int = 3) -> str:\n",
    "    base_prompt = f'''\n",
    "Return exactly ONE label: INFO, WARNING, CRITICAL\n",
    "Log: {message}\n",
    "Label:\n",
    "'''.strip()\n",
    "\n",
    "    prompt = base_prompt\n",
    "    for i in range(max_tries):\n",
    "        out = llm.invoke(prompt).content.strip().split()[0].upper()\n",
    "        if out in ALLOWED:\n",
    "            return out\n",
    "        # retry with stronger instruction\n",
    "        prompt = base_prompt + \"\\nRemember: output ONLY one of INFO/WARNING/CRITICAL.\"\n",
    "    return \"UNKNOWN\"\n",
    "\n",
    "tests = [\n",
    "    \"Security breach detected\",\n",
    "    \"Low disk space\",\n",
    "    \"All good, scheduled job ran\",\n",
    "]\n",
    "for t in tests:\n",
    "    print(t, \"->\", classify_with_retry(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db32dad",
   "metadata": {},
   "source": [
    "## 11) Batch processing with Pandas\n",
    "\n",
    "A realistic workflow: apply LLM classification to a column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1de2be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"message\": [\n",
    "        \"Database connection failed after deploy\",\n",
    "        \"Disk usage is 95% on node-2\",\n",
    "        \"Service started successfully\",\n",
    "        \"Latency spikes observed in API gateway\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "df[\"severity\"] = df[\"message\"].apply(classify_with_retry)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
